{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path\n",
    "data_dir = \"./data\"\n",
    "\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Load dataset\n",
    "batch_size = 256\n",
    "img_size = (160, 160)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "The dataset used in this project is available at the following link:  \n",
    "[Microsoft DigiFace-1M Dataset](https://github.com/microsoft/DigiFace1M)\n",
    "\n",
    "> The DigiFace-1M dataset is a collection of over one million diverse synthetic face images for face recognition.  \n",
    "> The DigiFace-1M dataset can be used for non-commercial research.  \n",
    ">   \n",
    "> The dataset contains:  \n",
    ">   \n",
    "> - 720K images with 10K identities (72 images per identity). For each identity, 4 different sets of accessories are sampled and 18 images are rendered for each set.  \n",
    "> - 500K images with 100K identities (5 images per identity). For each identity, only one set of accessories is sampled.\n",
    "\n",
    "From the dataset, I am using 32 folders, each representing a class of 3D-rendered synthetic people. Each folder includes 71 photos captured from different angles and lighting conditions.\n",
    "\n",
    "## Batch Size\n",
    "\n",
    "Batch size refers to the number of images processed by the model at once. In this case, 32 images are passed through the neural network per batch.\n",
    "\n",
    "- **Larger Batch Size**: Speeds up training but requires more memory.\n",
    "- **Smaller Batch Size**: Provides better generalization but slows down training.\n",
    "\n",
    "I tried 32, 64 and 128 in my testing 128 seemed to preform best for me\n",
    "\n",
    "## Image Size\n",
    "\n",
    "Images are resized to 160x160 pixels before being fed into the neural network. This ensures that all input images have the same dimensions for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5813 images belonging to 101 classes.\n",
      "Found 1403 images belonging to 101 classes.\n",
      "Class names: ['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', 'me']\n",
      "Number of classes: 101\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.6, 1.4),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_dataset = datagen.flow_from_directory(\n",
    "    \"data\",\n",
    "    target_size=(160, 160),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"training\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_dataset = datagen.flow_from_directory(\n",
    "    \"data\",\n",
    "    target_size=(160, 160),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"validation\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Get class names\n",
    "class_names = list(train_dataset.class_indices.keys())\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Ensure the number of classes matches the dataset\n",
    "num_classes = len(class_names)\n",
    "print(\"Number of classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DirectoryIterator to tf.data.Dataset\n",
    "train_dataset_eff = tf.data.Dataset.from_generator(\n",
    "\tlambda: train_dataset,\n",
    "\toutput_signature=(\n",
    "\t\ttf.TensorSpec(shape=(160, 160, 3), dtype=tf.float32),\n",
    "\t\ttf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "\t)\n",
    ")\n",
    "\n",
    "val_dataset_eff = tf.data.Dataset.from_generator(\n",
    "\tlambda: val_dataset,\n",
    "\toutput_signature=(\n",
    "\t\ttf.TensorSpec(shape=(160, 160, 3), dtype=tf.float32),\n",
    "\t\ttf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "\t)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(160, 160, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False  # Freeze base\n",
    "\n",
    "# Add your classifier head\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_160            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,029</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_160            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │        \u001b[38;5;34m13,029\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,434,981</span> (9.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,434,981\u001b[0m (9.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">176,997</span> (691.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m176,997\u001b[0m (691.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    # Stop training when validation loss stops improving\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate when validation loss plateaus\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Save best model\n",
    "    ModelCheckpoint(\n",
    "        'best_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.0098 - loss: 11.9058\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00998, saving model to best_model.keras\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 612ms/step - accuracy: 0.0098 - loss: 11.8754 - val_accuracy: 0.0100 - val_loss: 4.6416 - learning_rate: 0.1000\n",
      "Epoch 2/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - accuracy: 0.0095 - loss: 4.6840\n",
      "Epoch 2: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 553ms/step - accuracy: 0.0095 - loss: 4.6843 - val_accuracy: 0.0100 - val_loss: 4.6431 - learning_rate: 0.1000\n",
      "Epoch 3/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.0066 - loss: 4.6614\n",
      "Epoch 3: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 541ms/step - accuracy: 0.0066 - loss: 4.6614 - val_accuracy: 0.0100 - val_loss: 4.6441 - learning_rate: 0.1000\n",
      "Epoch 4/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.0074 - loss: 4.6609\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 532ms/step - accuracy: 0.0074 - loss: 4.6609 - val_accuracy: 0.0100 - val_loss: 4.6461 - learning_rate: 0.1000\n",
      "Epoch 5/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.0084 - loss: 4.6423\n",
      "Epoch 5: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 536ms/step - accuracy: 0.0084 - loss: 4.6423 - val_accuracy: 0.0100 - val_loss: 4.6231 - learning_rate: 0.0500\n",
      "Epoch 6/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.0058 - loss: 4.6389\n",
      "Epoch 6: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 538ms/step - accuracy: 0.0058 - loss: 4.6391 - val_accuracy: 0.0100 - val_loss: 4.6239 - learning_rate: 0.0500\n",
      "Epoch 7/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.0086 - loss: 4.6365\n",
      "Epoch 7: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 530ms/step - accuracy: 0.0086 - loss: 4.6366 - val_accuracy: 0.0100 - val_loss: 4.6222 - learning_rate: 0.0500\n",
      "Epoch 8/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.0127 - loss: 4.6294\n",
      "Epoch 8: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 458ms/step - accuracy: 0.0127 - loss: 4.6295 - val_accuracy: 0.0100 - val_loss: 4.6247 - learning_rate: 0.0500\n",
      "Epoch 9/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.0086 - loss: 4.6398\n",
      "Epoch 9: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 244ms/step - accuracy: 0.0086 - loss: 4.6398 - val_accuracy: 0.0100 - val_loss: 4.6285 - learning_rate: 0.0500\n",
      "Epoch 10/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.0065 - loss: 4.6313\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 256ms/step - accuracy: 0.0065 - loss: 4.6313 - val_accuracy: 0.0100 - val_loss: 4.6235 - learning_rate: 0.0500\n",
      "Epoch 11/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0087 - loss: 4.6322\n",
      "Epoch 11: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 252ms/step - accuracy: 0.0087 - loss: 4.6322 - val_accuracy: 0.0100 - val_loss: 4.6140 - learning_rate: 0.0250\n",
      "Epoch 12/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0072 - loss: 4.6210\n",
      "Epoch 12: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 253ms/step - accuracy: 0.0072 - loss: 4.6210 - val_accuracy: 0.0100 - val_loss: 4.6142 - learning_rate: 0.0250\n",
      "Epoch 13/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.0070 - loss: 4.6226\n",
      "Epoch 13: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 254ms/step - accuracy: 0.0070 - loss: 4.6226 - val_accuracy: 0.0100 - val_loss: 4.6141 - learning_rate: 0.0250\n",
      "Epoch 14/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0060 - loss: 4.6225\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 252ms/step - accuracy: 0.0060 - loss: 4.6225 - val_accuracy: 0.0100 - val_loss: 4.6153 - learning_rate: 0.0250\n",
      "Epoch 15/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.0107 - loss: 4.6161\n",
      "Epoch 15: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 219ms/step - accuracy: 0.0107 - loss: 4.6161 - val_accuracy: 0.0100 - val_loss: 4.6115 - learning_rate: 0.0125\n",
      "Epoch 16/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0089 - loss: 4.6154\n",
      "Epoch 16: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 206ms/step - accuracy: 0.0089 - loss: 4.6155 - val_accuracy: 0.0100 - val_loss: 4.6112 - learning_rate: 0.0125\n",
      "Epoch 17/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0080 - loss: 4.6168\n",
      "Epoch 17: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0079 - loss: 4.6168 - val_accuracy: 0.0100 - val_loss: 4.6227 - learning_rate: 0.0125\n",
      "Epoch 18/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0079 - loss: 4.6152\n",
      "Epoch 18: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0079 - loss: 4.6152 - val_accuracy: 0.0100 - val_loss: 4.6111 - learning_rate: 0.0125\n",
      "Epoch 19/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0073 - loss: 4.6148\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0073 - loss: 4.6149 - val_accuracy: 0.0100 - val_loss: 4.6112 - learning_rate: 0.0125\n",
      "Epoch 20/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0081 - loss: 4.6117\n",
      "Epoch 20: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 206ms/step - accuracy: 0.0081 - loss: 4.6118 - val_accuracy: 0.0100 - val_loss: 4.6108 - learning_rate: 0.0063\n",
      "Epoch 21/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0124 - loss: 4.6134\n",
      "Epoch 21: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0124 - loss: 4.6134 - val_accuracy: 0.0100 - val_loss: 4.6107 - learning_rate: 0.0063\n",
      "Epoch 22/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0108 - loss: 4.6129\n",
      "Epoch 22: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 206ms/step - accuracy: 0.0107 - loss: 4.6129 - val_accuracy: 0.0100 - val_loss: 4.6107 - learning_rate: 0.0063\n",
      "Epoch 23/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0116 - loss: 4.6148\n",
      "Epoch 23: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0116 - loss: 4.6148 - val_accuracy: 0.0100 - val_loss: 4.6231 - learning_rate: 0.0063\n",
      "Epoch 24/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0087 - loss: 4.6121\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0087 - loss: 4.6121 - val_accuracy: 0.0100 - val_loss: 4.6107 - learning_rate: 0.0063\n",
      "Epoch 25/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0100 - loss: 4.6117\n",
      "Epoch 25: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0100 - loss: 4.6117 - val_accuracy: 0.0100 - val_loss: 4.6107 - learning_rate: 0.0031\n",
      "Epoch 26/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0093 - loss: 4.6120\n",
      "Epoch 26: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0093 - loss: 4.6120 - val_accuracy: 0.0100 - val_loss: 4.6107 - learning_rate: 0.0031\n",
      "Epoch 27/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0071 - loss: 4.6122\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0071 - loss: 4.6122 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 0.0031\n",
      "Epoch 28/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0090 - loss: 4.6105\n",
      "Epoch 28: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0090 - loss: 4.6105 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 0.0016\n",
      "Epoch 29/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0113 - loss: 4.6100\n",
      "Epoch 29: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0113 - loss: 4.6100 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 0.0016\n",
      "Epoch 30/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0092 - loss: 4.6116\n",
      "Epoch 30: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0092 - loss: 4.6116 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0056 - loss: 4.6113\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0056 - loss: 4.6113 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 0.0016\n",
      "Epoch 32/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0082 - loss: 4.6101\n",
      "Epoch 32: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0082 - loss: 4.6101 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 7.8125e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0058 - loss: 4.6100\n",
      "Epoch 33: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0058 - loss: 4.6101 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 7.8125e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0074 - loss: 4.6125\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0003906250058207661.\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0074 - loss: 4.6125 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 7.8125e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0071 - loss: 4.6099\n",
      "Epoch 35: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0071 - loss: 4.6100 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 3.9063e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0061 - loss: 4.6100\n",
      "Epoch 36: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0061 - loss: 4.6100 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 3.9063e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0094 - loss: 4.6106\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00019531250291038305.\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0094 - loss: 4.6106 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 3.9063e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0064 - loss: 4.6108\n",
      "Epoch 38: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0065 - loss: 4.6108 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 1.9531e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0096 - loss: 4.6110\n",
      "Epoch 39: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0096 - loss: 4.6110 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 1.9531e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0106 - loss: 4.6103\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 9.765625145519152e-05.\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0106 - loss: 4.6104 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 1.9531e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0104 - loss: 4.6108\n",
      "Epoch 41: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0104 - loss: 4.6108 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 9.7656e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0102 - loss: 4.6093\n",
      "Epoch 42: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0102 - loss: 4.6093 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 9.7656e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0106 - loss: 4.6103\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.882812572759576e-05.\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0106 - loss: 4.6103 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 9.7656e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0122 - loss: 4.6102\n",
      "Epoch 44: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0122 - loss: 4.6102 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 4.8828e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0119 - loss: 4.6110\n",
      "Epoch 45: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0119 - loss: 4.6110 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 4.8828e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0104 - loss: 4.6109\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 2.441406286379788e-05.\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0104 - loss: 4.6109 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 4.8828e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.0101 - loss: 4.6099\n",
      "Epoch 47: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 205ms/step - accuracy: 0.0101 - loss: 4.6099 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 2.4414e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0102 - loss: 4.6115\n",
      "Epoch 48: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0102 - loss: 4.6115 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 2.4414e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.0093 - loss: 4.6102\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.220703143189894e-05.\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.0093 - loss: 4.6102 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 2.4414e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.0100 - loss: 4.6122\n",
      "Epoch 50: val_accuracy did not improve from 0.00998\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 204ms/step - accuracy: 0.0100 - loss: 4.6122 - val_accuracy: 0.0100 - val_loss: 4.6106 - learning_rate: 1.2207e-05\n",
      "Restoring model weights from the end of the best epoch: 49.\n"
     ]
    }
   ],
   "source": [
    "# Train the model with a large number of max epochs\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('model.h5')\n",
    "print(\"Model saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - accuracy: 0.0092 - loss: 4.6107\n",
      "Test Accuracy: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "test_loss, test_acc = model.evaluate(val_dataset)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training performance\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy / Loss')\n",
    "plt.legend()\n",
    "plt.title('Model 1 Training Performance')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
